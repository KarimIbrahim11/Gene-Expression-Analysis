{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation \n",
    "#### This notebook is used to transform the data from it's Original Format to a one more suited for the study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Necessary Libraries and setting up logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.data import *\n",
    "from src.utils.memory_management import *\n",
    "from src.configs.config_parser import PathConfigParser, data_config_file, project_root\n",
    "\n",
    "# Set up logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create a console handler\n",
    "sh = logging.StreamHandler()\n",
    "sh.setLevel(logging.INFO)\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Configs from Config Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs Directory\n",
    "parser = PathConfigParser(str(data_config_file))\n",
    "parser.load()\n",
    "\n",
    "# Access paths\n",
    "RAW_DATA_PATH = project_root / parser.get(\"data_paths\", {}).get(\"raw_data\") \n",
    "PROCESSED_DATA_PATH = project_root / parser.get(\"data_paths\", {}).get(\"processed_data\")\n",
    "GE_PATH = parser.get(\"data_paths\", {}).get(\"brain_regions_genes_ge\")\n",
    "PROCESSED_DONORS_GE_PATH = PROCESSED_DATA_PATH / GE_PATH\n",
    "\n",
    "# Donors_ids\n",
    "DONORS_IDS = parser.get(\"donors_ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading from URL: https://human.brain-map.org/api/v2/well_known_file_download/178238387\n",
      "Downloading from URL: https://human.brain-map.org/api/v2/well_known_file_download/178238387\n",
      "normalized_microarray_donor9861.zip: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426M/426M [07:34<00:00, 938kB/s]\n",
      "Downloaded: normalized_microarray_donor9861.zip\n",
      "Downloaded: normalized_microarray_donor9861.zip\n",
      "Unzipped: /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor9861.zip\n",
      "Unzipped: /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor9861.zip\n",
      "Downloading from URL: https://human.brain-map.org/api/v2/well_known_file_download/178238373\n",
      "Downloading from URL: https://human.brain-map.org/api/v2/well_known_file_download/178238373\n",
      "normalized_microarray_donor10021.zip: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401M/401M [14:02<00:00, 476kB/s]\n",
      "Downloaded: normalized_microarray_donor10021.zip\n",
      "Downloaded: normalized_microarray_donor10021.zip\n",
      "Unzipped: /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor10021.zip\n",
      "Unzipped: /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor10021.zip\n",
      "Downloading from URL: https://human.brain-map.org/api/v2/well_known_file_download/178238359\n",
      "Downloading from URL: https://human.brain-map.org/api/v2/well_known_file_download/178238359\n",
      "normalized_microarray_donor12876.zip: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 166M/166M [04:08<00:00, 669kB/s]\n",
      "Downloaded: normalized_microarray_donor12876.zip\n",
      "Downloaded: normalized_microarray_donor12876.zip\n",
      "Unzipped: /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor12876.zip\n",
      "Unzipped: /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor12876.zip\n",
      "Downloading from URL: https://human.brain-map.org/api/v2/well_known_file_download/178238316\n",
      "Downloading from URL: https://human.brain-map.org/api/v2/well_known_file_download/178238316\n",
      "normalized_microarray_donor14380.zip: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241M/241M [04:57<00:00, 812kB/s]\n",
      "Downloaded: normalized_microarray_donor14380.zip\n",
      "Downloaded: normalized_microarray_donor14380.zip\n",
      "Unzipped: /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor14380.zip\n",
      "Unzipped: /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor14380.zip\n",
      "Downloading from URL: https://human.brain-map.org/api/v2/well_known_file_download/178238266\n",
      "Downloading from URL: https://human.brain-map.org/api/v2/well_known_file_download/178238266\n",
      "normalized_microarray_donor15496.zip: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 216M/216M [05:37<00:00, 640kB/s]\n",
      "Downloaded: normalized_microarray_donor15496.zip\n",
      "Downloaded: normalized_microarray_donor15496.zip\n",
      "Unzipped: /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor15496.zip\n",
      "Unzipped: /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor15496.zip\n",
      "Downloading from URL: https://human.brain-map.org/api/v2/well_known_file_download/178236545\n",
      "Downloading from URL: https://human.brain-map.org/api/v2/well_known_file_download/178236545\n",
      "normalized_microarray_donor15697.zip: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 231M/231M [03:08<00:00, 1.22MB/s]\n",
      "Downloaded: normalized_microarray_donor15697.zip\n",
      "Downloaded: normalized_microarray_donor15697.zip\n",
      "Unzipped: /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor15697.zip\n",
      "Unzipped: /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor15697.zip\n"
     ]
    }
   ],
   "source": [
    "with open(project_root/ Path(\"data/download_dataset.py\")) as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions for the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sample_annotations(donor_sa: pd.DataFrame, left_mask : pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Transforming Sample Annotations initial files\n",
    "    \"\"\"\n",
    "    # Keep certain columns in the SampleAnnot.csv file\n",
    "    donor_sa_processed = keep_df_cols(donor_sa, [\"structure_id\", \"structure_name\"])\n",
    "    deallocate_df(donor_sa)\n",
    "    # Applying mask on Sample annotations file\n",
    "    donor_sa_filtered= donor_sa_processed[left_mask].reset_index(drop=True)\n",
    "    deallocate_df(donor_sa_processed)\n",
    "    return donor_sa_filtered\n",
    "\n",
    "def transform_gene_expressions(donor_ge: pd.DataFrame, left_mask : pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Transforming Gene Expression initial files\n",
    "    \"\"\"\n",
    "    # Applying mask on the Columns of the donor_ge file\n",
    "    left_mask_ge = pd.concat([pd.Series([True], index=[0]), left_mask], ignore_index=True)\n",
    "    left_mask_ge_filtered = left_mask_ge[left_mask_ge].index.values.tolist()\n",
    "    donor_ge_filtered  = donor_ge.iloc[:, left_mask_ge_filtered]\n",
    "    deallocate_df(donor_ge)\n",
    "    return donor_ge_filtered\n",
    "\n",
    "def write_geneexpressions_to_json(df: pd.DataFrame, pth: Path) -> None:\n",
    "    \"\"\"\n",
    "        Specific to writing gene_expression files to json and keep the lists as numbers\n",
    "    \"\"\"\n",
    "    # Ensure 'gene_expression_values' is a list, not a string\n",
    "    df[\"gene_expression_values\"] = df[\"gene_expression_values\"].apply(\n",
    "        lambda x: literal_eval(x) if isinstance(x, str) else x\n",
    "    )\n",
    "    # Group by `brain_region`\n",
    "    grouped = (\n",
    "        df.groupby(\"brain_region\")\n",
    "        .apply(lambda x: x[[\"gene_id\", \"gene_expression_values\"]].to_dict(orient=\"records\"))\n",
    "        .to_dict()\n",
    "    )\n",
    "    # Change group keys to number\n",
    "    grouped = {int(key): value for key, value in grouped.items()}\n",
    "\n",
    "    # Write grouped data to JSON\n",
    "    with open(pth, \"w\") as f:\n",
    "        json.dump(grouped, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Grouped CSV Files for each Donor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a regex to load the files based upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_pattern = r\"^normalized_microarray_donor\\d+$\"\n",
    "donor_dirs = [d for d in RAW_DATA_PATH.iterdir() if d.is_dir() and re.match(donor_pattern, d.name)]\n",
    "donors_ges = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the files and processing them individually in `data/processed/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data of /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor10021\n",
      "Processing data of /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor14380\n",
      "Processing data of /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor9861\n",
      "Processing data of /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor15496\n",
      "Processing data of /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor12876\n",
      "Processing data of /home/affectiva/git/Gene-Expression-Analysis/data/raw/normalized_microarray_donor15697\n"
     ]
    }
   ],
   "source": [
    "for donor_path in donor_dirs:\n",
    "    # Processing path\n",
    "    logger.info(f\"Processing data of {donor_path}\")\n",
    "\n",
    "    # Processing SampleAnnot to get the brain region id (\"structure id\")\n",
    "    donor_sa = load_df_from_csv(donor_path / \"SampleAnnot.csv\")\n",
    "    # Create a mask for left hemisphere entries\n",
    "    left_mask = mask_left_hemisphere(donor_sa)\n",
    "    # Transform donor_sa\n",
    "    donor_sa_filtered = transform_sample_annotations(donor_sa, left_mask)\n",
    "\n",
    "    # Loading Gene Expressions\n",
    "    donor_ge = load_df_from_csv(donor_path / \"MicroarrayExpression.csv\")\n",
    "    # Transform Gene Expressions\n",
    "    donor_ge_filtered = transform_gene_expressions(donor_ge, left_mask)\n",
    "    # Load probes data \n",
    "    donor_probes = load_df_from_csv(donor_path / \"Probes.csv\")\n",
    "    # Add Brain Region id as a column name in the gene_expression data\n",
    "    donor_ge_filtered.columns = ['probe_id'] + list(donor_sa_filtered[\"structure_id\"])\n",
    "    deallocate_df(donor_sa_filtered)\n",
    "    # Add gene_id Column in the gene_expressions data\n",
    "    donor_ge_filtered.insert(0, 'gene_id', donor_probes['gene_id'])\n",
    "\n",
    "    # Drop probe_id column        \n",
    "    donor_ge_filtered = donor_ge_filtered.drop(columns=['probe_id'])\n",
    "    \n",
    "    # Create a new CSV with grouped gene_ids by melting the DataFrame to make it easier to manipulate\n",
    "    df_melted = donor_ge_filtered.melt(id_vars=[\"gene_id\"], var_name=\"brain_region\", value_name=\"gene_expression_values\")\n",
    "    # Now, group by brain_region and gene_id  and aggregate the test values into lists\n",
    "    df_grouped = df_melted.groupby([\"brain_region\", \"gene_id\"])[\"gene_expression_values\"].apply(list).reset_index()\n",
    "    # *Apply json dumps to be able to load the file appropiately\n",
    "    df_grouped[\"gene_expression_values\"] = df_grouped[\"gene_expression_values\"].apply(json.dumps)\n",
    "    # Save the grouped csvs per each donor\n",
    "    write_df_to_csv(df_grouped, PROCESSED_DATA_PATH / f\"brain_regions_genes_geneexpressions/{get_donor_id_from_path(donor_path)}_grouped.csv\")\n",
    "    deallocate_df(df_melted)\n",
    "    deallocate_df(donor_ge_filtered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Donor CSV Creation and Selecting only Common brain regions for the study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating `meta_donor.csv` which is the file having the combined data from all donors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Donor Id: 9861\n",
      "Number of brain regions: 156\n",
      "Number of gene ids: 29179\n",
      "Donor Id: 10021\n",
      "Number of brain regions: 162\n",
      "Number of gene ids: 29179\n",
      "Donor Id: 12876\n",
      "Number of brain regions: 155\n",
      "Number of gene ids: 29179\n",
      "Donor Id: 14380\n",
      "Number of brain regions: 179\n",
      "Number of gene ids: 29179\n",
      "Donor Id: 15496\n",
      "Number of brain regions: 172\n",
      "Number of gene ids: 29179\n",
      "Donor Id: 15697\n",
      "Number of brain regions: 185\n",
      "Number of gene ids: 29179\n"
     ]
    }
   ],
   "source": [
    "donor_ges = []\n",
    "for donor in DONORS_IDS:\n",
    "    # Load donor .csv from processed data \n",
    "    donor_ge = load_df_from_csv(PROCESSED_DONORS_GE_PATH / Path(f\"{donor}_grouped.csv\"))\n",
    "    logger.info(f\"Donor Id: {str(donor)}\")\n",
    "    logger.info(f\"Number of brain regions: {donor_ge['brain_region'].nunique()}\")\n",
    "    logger.info(f\"Number of gene ids: {donor_ge['gene_id'].nunique()}\")\n",
    "    donor_ge[\"gene_expression_values\"]=donor_ge[\"gene_expression_values\"].apply(json.loads)\n",
    "    donor_ges.append(donor_ge)\n",
    "    deallocate_df(donor_ge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of common brain regions: 103\n",
      "meta_donor_df size:18032622\n",
      "Meta Donor DF has only list of common_brain_regions: True\n"
     ]
    }
   ],
   "source": [
    "# Finding common brain regions and filtering the others out\n",
    "common_brain_regions = set.intersection(*(set(donor_ge['brain_region']) for donor_ge in donor_ges))\n",
    "logger.info(f\"Number of common brain regions: {len(common_brain_regions)}\")\n",
    "\n",
    "# Keep only the common columns in each DataFrame\n",
    "filtered_donors_ges = [donor_ge[donor_ge['brain_region'].isin(common_brain_regions)] for donor_ge in donor_ges]\n",
    "set(filtered_donors_ges[3]['brain_region'])==common_brain_regions\n",
    "\n",
    "# Concatenate all filtered DataFrames\n",
    "meta_donor_df = pd.concat(filtered_donors_ges, ignore_index=True)\n",
    "logger.info(f\"meta_donor_df size:{len(meta_donor_df)}\")\n",
    "logger.info(f\"Meta Donor DF has only list of common_brain_regions: {set(meta_donor_df['brain_region'])==common_brain_regions}\")\n",
    "\n",
    "concatenated_ges = meta_donor_df.groupby([\"brain_region\", \"gene_id\"])[\"gene_expression_values\"].apply(lambda x: sum(x, [])).reset_index()\n",
    "\n",
    "write_df_to_csv(concatenated_ges, PROCESSED_DONORS_GE_PATH / f\"meta_donor.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Transforming files to .json for hierarchal structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating donor id: 9861 json file\n"
     ]
    }
   ],
   "source": [
    "# Creating Json files for Hierarchal Data\n",
    "for donor in DONORS_IDS:\n",
    "    logger.info(f\"Creating donor id: {str(donor)} json file\")\n",
    "    # Load donor csv from processed data \n",
    "    donor_ge = load_df_from_csv(PROCESSED_DONORS_GE_PATH / Path(f\"{donor}_grouped.csv\"))\n",
    "    write_geneexpressions_to_json(donor_ge, PROCESSED_DONORS_GE_PATH / Path(f\"{donor}_grouped.json\"))\n",
    "# Creating Meta Donor Json File\n",
    "logger.info(f\"Creating meta_donor.json file\")\n",
    "meta_donor_ge = load_df_from_csv(PROCESSED_DONORS_GE_PATH / Path(f\"meta_donor.csv\"))\n",
    "write_geneexpressions_to_json(meta_donor_ge, PROCESSED_DONORS_GE_PATH / Path(f\"meta_donor.json\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
